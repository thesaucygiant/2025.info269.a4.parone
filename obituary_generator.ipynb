{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obituary Generator with Claude\n",
    "\n",
    "This notebook generates obituaries from uploaded PDF or text files and allows conversational follow-up with Claude.\n",
    "\n",
    "## Setup Instructions\n",
    "1. Install required packages\n",
    "2. Add your Anthropic API key\n",
    "3. Upload a document about the person\n",
    "4. Generate and refine the obituary through conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install anthropic pypdf ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import os\n",
    "from pypdf import PdfReader\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure API Key\n",
    "\n",
    "Enter your Anthropic API key below. You can get one from: https://console.anthropic.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your API key here\n",
    "API_KEY = \"\"  # Replace with your actual API key\n",
    "\n",
    "# Or use environment variable\n",
    "if not API_KEY:\n",
    "    API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\", \"\")\n",
    "\n",
    "if not API_KEY:\n",
    "    print(\"âš ï¸ Please set your API key above or in the ANTHROPIC_API_KEY environment variable\")\n",
    "else:\n",
    "    print(\"âœ“ API key configured\")\n",
    "    client = anthropic.Anthropic(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"\n",
    "    Extract text content from a PDF file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_file: File object or path to PDF\n",
    "    \n",
    "    Returns:\n",
    "        Extracted text as string\n",
    "    \"\"\"\n",
    "    reader = PdfReader(pdf_file)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def read_text_file(text_file):\n",
    "    \"\"\"\n",
    "    Read content from a text file.\n",
    "    \n",
    "    Args:\n",
    "        text_file: File object or path to text file\n",
    "    \n",
    "    Returns:\n",
    "        File content as string\n",
    "    \"\"\"\n",
    "    if isinstance(text_file, str):\n",
    "        with open(text_file, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "    else:\n",
    "        return text_file.read().decode('utf-8')\n",
    "\n",
    "class ObituaryGenerator:\n",
    "    \"\"\"\n",
    "    Manages obituary generation and conversational follow-ups.\n",
    "    Keeps track of the full conversation history with Claude.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "        self.client = anthropic.Anthropic(api_key=api_key)\n",
    "        self.conversation_history = []  # Stores all messages\n",
    "        self.document_content = None\n",
    "        \n",
    "    def load_document(self, file_content, file_type='text'):\n",
    "        \"\"\"\n",
    "        Load and store document content.\n",
    "        \n",
    "        Args:\n",
    "            file_content: The text content or file object\n",
    "            file_type: 'text' or 'pdf'\n",
    "        \"\"\"\n",
    "        if file_type == 'pdf':\n",
    "            self.document_content = extract_text_from_pdf(io.BytesIO(file_content))\n",
    "        else:\n",
    "            self.document_content = file_content if isinstance(file_content, str) else file_content.decode('utf-8')\n",
    "        \n",
    "        print(f\"âœ“ Document loaded ({len(self.document_content)} characters)\")\n",
    "    \n",
    "    def generate_initial_obituary(self):\n",
    "        \"\"\"\n",
    "        Generate the first obituary from the document.\n",
    "        This starts a new conversation.\n",
    "        \"\"\"\n",
    "        if not self.document_content:\n",
    "            return \"Please load a document first!\"\n",
    "        \n",
    "        # Create initial prompt\n",
    "        initial_prompt = f\"\"\"Based on the following information about a person, please write a thoughtful and respectful obituary. \n",
    "Include key life events, achievements, family connections, and what made them special.\n",
    "\n",
    "Document content:\n",
    "{self.document_content}\n",
    "\n",
    "Please generate a well-structured obituary.\"\"\"\n",
    "        \n",
    "        # Start new conversation\n",
    "        self.conversation_history = [\n",
    "            {\"role\": \"user\", \"content\": initial_prompt}\n",
    "        ]\n",
    "        \n",
    "        # Call Claude API\n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-sonnet-4-20250514\",\n",
    "            max_tokens=2000,\n",
    "            messages=self.conversation_history\n",
    "        )\n",
    "        \n",
    "        # Add Claude's response to history\n",
    "        assistant_message = response.content[0].text\n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": assistant_message\n",
    "        })\n",
    "        \n",
    "        return assistant_message\n",
    "    \n",
    "    def follow_up(self, user_message):\n",
    "        \"\"\"\n",
    "        Send a follow-up message in the conversation.\n",
    "        This maintains the full conversation context.\n",
    "        \n",
    "        Args:\n",
    "            user_message: The follow-up question or instruction\n",
    "        \n",
    "        Returns:\n",
    "            Claude's response\n",
    "        \"\"\"\n",
    "        if not self.conversation_history:\n",
    "            return \"Please generate an initial obituary first!\"\n",
    "        \n",
    "        # Add user's follow-up to conversation\n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_message\n",
    "        })\n",
    "        \n",
    "        # Call Claude with full conversation history\n",
    "        response = self.client.messages.create(\n",
    "            model=\"claude-sonnet-4-20250514\",\n",
    "            max_tokens=2000,\n",
    "            messages=self.conversation_history\n",
    "        )\n",
    "        \n",
    "        # Add Claude's response to history\n",
    "        assistant_message = response.content[0].text\n",
    "        self.conversation_history.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": assistant_message\n",
    "        })\n",
    "        \n",
    "        return assistant_message\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Clear the conversation history and start fresh.\"\"\"\n",
    "        self.conversation_history = []\n",
    "        print(\"âœ“ Conversation reset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Initialize the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the obituary generator instance\n",
    "generator = ObituaryGenerator(API_KEY)\n",
    "print(\"âœ“ Generator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Upload and Load Your Document\n",
    "\n",
    "Choose one of the following options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: Upload a file using the file uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File uploader widget\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.pdf,.txt',\n",
    "    multiple=False,\n",
    "    description='Upload File'\n",
    ")\n",
    "\n",
    "def on_file_upload(change):\n",
    "    \"\"\"Handle file upload event\"\"\"\n",
    "    if uploader.value:\n",
    "        uploaded_file = list(uploader.value.values())[0]\n",
    "        file_name = list(uploader.value.keys())[0]\n",
    "        \n",
    "        # Determine file type\n",
    "        file_type = 'pdf' if file_name.endswith('.pdf') else 'text'\n",
    "        \n",
    "        # Load the document\n",
    "        generator.load_document(uploaded_file['content'], file_type)\n",
    "        print(f\"âœ“ Loaded: {file_name}\")\n",
    "\n",
    "uploader.observe(on_file_upload, names='value')\n",
    "display(uploader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Paste text directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or paste your text here\n",
    "document_text = \"\"\"\n",
    "Paste information about the person here...\n",
    "\"\"\"\n",
    "\n",
    "# Uncomment the line below to load the pasted text\n",
    "# generator.load_document(document_text, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generate Initial Obituary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the initial obituary\n",
    "print(\"Generating obituary...\\n\")\n",
    "obituary = generator.generate_initial_obituary()\n",
    "display(Markdown(\"## Generated Obituary\\n\\n\" + obituary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Interactive Follow-up Conversation\n",
    "\n",
    "Now you can refine the obituary through conversation! Run this cell and ask follow-up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widgets for follow-up\n",
    "follow_up_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Ask a follow-up question or request changes (e.g., \"Make it shorter\", \"Add more about their career\", \"Make it more personal\")',\n",
    "    description='Follow-up:',\n",
    "    layout=widgets.Layout(width='100%', height='80px')\n",
    ")\n",
    "\n",
    "submit_button = widgets.Button(\n",
    "    description='Send',\n",
    "    button_style='primary',\n",
    "    tooltip='Send follow-up message'\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_submit_click(b):\n",
    "    \"\"\"Handle follow-up submission\"\"\"\n",
    "    user_message = follow_up_input.value.strip()\n",
    "    \n",
    "    if not user_message:\n",
    "        with output_area:\n",
    "            print(\"Please enter a message!\")\n",
    "        return\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"You: {user_message}\\n\")\n",
    "        print(\"Claude is thinking...\\n\")\n",
    "    \n",
    "    # Get response from Claude\n",
    "    response = generator.follow_up(user_message)\n",
    "    \n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        display(Markdown(f\"**You:** {user_message}\\n\\n**Claude:**\\n\\n{response}\"))\n",
    "    \n",
    "    # Clear input\n",
    "    follow_up_input.value = ''\n",
    "\n",
    "submit_button.on_click(on_submit_click)\n",
    "\n",
    "# Display the interface\n",
    "display(widgets.VBox([follow_up_input, submit_button, output_area]))\n",
    "\n",
    "print(\"\\nðŸ’¡ Examples of follow-up prompts you can try:\")\n",
    "print(\"  â€¢ Make it shorter and more concise\")\n",
    "print(\"  â€¢ Add more emphasis on their family life\")\n",
    "print(\"  â€¢ Make the tone more celebratory\")\n",
    "print(\"  â€¢ Include specific dates and locations\")\n",
    "print(\"  â€¢ Rewrite in a different style\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: View Full Conversation History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the complete conversation\n",
    "print(f\"Total messages in conversation: {len(generator.conversation_history)}\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, message in enumerate(generator.conversation_history, 1):\n",
    "    role = \"You\" if message[\"role\"] == \"user\" else \"Claude\"\n",
    "    content = message[\"content\"]\n",
    "    \n",
    "    # Truncate very long messages for display\n",
    "    if len(content) > 500:\n",
    "        content = content[:500] + \"... (truncated)\"\n",
    "    \n",
    "    print(f\"\\n[Message {i}] {role}:\")\n",
    "    print(content)\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Reset and Start Over (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the conversation and start fresh\n",
    "generator.reset_conversation()\n",
    "print(\"You can now go back to Step 7 to generate a new obituary!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage Summary\n",
    "\n",
    "**How this works:**\n",
    "\n",
    "1. **Conversation Memory**: The `ObituaryGenerator` class keeps a `conversation_history` list that stores ALL messages between you and Claude\n",
    "\n",
    "2. **Initial Generation**: When you first generate an obituary, it creates a conversation with:\n",
    "   - Your initial request + document content\n",
    "   - Claude's obituary response\n",
    "\n",
    "3. **Follow-ups**: Each time you send a follow-up:\n",
    "   - Your message is added to the history\n",
    "   - The ENTIRE history is sent to Claude (so it remembers everything)\n",
    "   - Claude's new response is added to the history\n",
    "\n",
    "4. **Why this matters**: Claude can remember and reference:\n",
    "   - The original document content\n",
    "   - The obituary it wrote\n",
    "   - All your previous requests and changes\n",
    "\n",
    "This is exactly what Assignment 4 is asking for - demonstrating proper conversation management!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
