{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ancestor RAG System - Complete Interactive Notebook\n",
    "\n",
    "This notebook demonstrates RAG (Retrieval Augmented Generation) for querying ancestor PDFs.\n",
    "\n",
    "## üìã What This Demo Does:\n",
    "\n",
    "1. ‚úÖ Prompts for API key\n",
    "2. ‚úÖ Asks a question BEFORE loading PDFs (baseline)\n",
    "3. ‚úÖ Lets you select which PDFs to load\n",
    "4. ‚úÖ Times the RAG embedding process\n",
    "5. ‚úÖ Asks the same question AFTER loading (with RAG)\n",
    "6. ‚úÖ Shows before/after comparison\n",
    "7. ‚úÖ Interactive Q&A mode\n",
    "\n",
    "## üöÄ Quick Start:\n",
    "\n",
    "1. Upload your PDF files to this directory\n",
    "2. Run all cells: **Cell ‚Üí Run All**\n",
    "3. Follow the prompts!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "!pip install anthropic pypdf numpy scikit-learn ipywidgets -q\n",
    "\n",
    "print(\"‚úì Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any, Optional\n",
    "import time\n",
    "import pickle\n",
    "import anthropic\n",
    "from pypdf import PdfReader\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from IPython.display import display, HTML, Markdown, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Step 3: Define AncestorRAG Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AncestorRAG:\n",
    "    \"\"\"\n",
    "    A RAG system for ancestor research using only Anthropic's Claude API.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, anthropic_api_key: str):\n",
    "        \"\"\"Initialize the RAG system.\"\"\"\n",
    "        self.api_key = anthropic_api_key\n",
    "        self.client = anthropic.Anthropic(api_key=self.api_key)\n",
    "        self.documents = []  # Store document chunks\n",
    "        self.embeddings = []  # Store embeddings\n",
    "        print(\"‚úì Ancestor RAG system initialized\")\n",
    "    \n",
    "    def extract_text_from_pdf(self, pdf_path: str) -> str:\n",
    "        \"\"\"Extract all text content from a PDF file.\"\"\"\n",
    "        try:\n",
    "            reader = PdfReader(pdf_path)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text + \"\\n\"\n",
    "            return text\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {pdf_path}: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def chunk_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:\n",
    "        \"\"\"Split text into overlapping chunks.\"\"\"\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        \n",
    "        while start < len(text):\n",
    "            end = start + chunk_size\n",
    "            chunk = text[start:end].strip()\n",
    "            if chunk:\n",
    "                chunks.append(chunk)\n",
    "            start += chunk_size - overlap\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def create_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Create simple embedding using word hashing.\"\"\"\n",
    "        text = text.lower()\n",
    "        words = text.split()\n",
    "        embedding_dim = 512\n",
    "        embedding = np.zeros(embedding_dim)\n",
    "        \n",
    "        for word in words:\n",
    "            hash_val = hash(word) % embedding_dim\n",
    "            embedding[hash_val] += 1\n",
    "        \n",
    "        norm = np.linalg.norm(embedding)\n",
    "        if norm > 0:\n",
    "            embedding = embedding / norm\n",
    "        \n",
    "        return embedding.tolist()\n",
    "    \n",
    "    def add_pdf(self, pdf_path: str, metadata: Optional[Dict[str, Any]] = None):\n",
    "        \"\"\"Add a PDF document to the RAG system.\"\"\"\n",
    "        if not os.path.exists(pdf_path):\n",
    "            print(f\"‚ùå Error: File not found: {pdf_path}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üìÑ Processing {pdf_path}...\")\n",
    "        \n",
    "        # Extract text\n",
    "        text = self.extract_text_from_pdf(pdf_path)\n",
    "        if not text.strip():\n",
    "            print(f\"‚ùå Warning: No text extracted from {pdf_path}\")\n",
    "            return\n",
    "        \n",
    "        # Split into chunks\n",
    "        chunks = self.chunk_text(text)\n",
    "        if not chunks:\n",
    "            print(f\"‚ùå Warning: No chunks created from {pdf_path}\")\n",
    "            return\n",
    "        \n",
    "        print(f\"   Creating embeddings for {len(chunks)} chunks...\")\n",
    "        \n",
    "        # Create embeddings\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            embedding = self.create_embedding(chunk)\n",
    "            doc_metadata = metadata.copy() if metadata else {}\n",
    "            doc_metadata.update({\n",
    "                \"source\": pdf_path,\n",
    "                \"filename\": Path(pdf_path).name,\n",
    "                \"chunk_id\": i,\n",
    "                \"total_chunks\": len(chunks)\n",
    "            })\n",
    "            \n",
    "            self.documents.append({\"text\": chunk, \"metadata\": doc_metadata})\n",
    "            self.embeddings.append(embedding)\n",
    "        \n",
    "        print(f\"‚úì Added {len(chunks)} chunks from {Path(pdf_path).name}\")\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search for relevant document chunks.\"\"\"\n",
    "        if not self.documents:\n",
    "            return []\n",
    "        \n",
    "        query_embedding = self.create_embedding(query)\n",
    "        similarities = cosine_similarity([query_embedding], self.embeddings)[0]\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                \"text\": self.documents[idx][\"text\"],\n",
    "                \"metadata\": self.documents[idx][\"metadata\"],\n",
    "                \"score\": float(similarities[idx])\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def query(self, question: str, top_k: int = 5, show_sources: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"Answer a question using RAG with Claude.\"\"\"\n",
    "        if not self.documents:\n",
    "            return {\n",
    "                \"answer\": \"No documents loaded. Please add PDF files first.\",\n",
    "                \"sources\": []\n",
    "            }\n",
    "        \n",
    "        # Retrieve relevant documents\n",
    "        results = self.search(question, top_k=top_k)\n",
    "        \n",
    "        # Build context\n",
    "        context_parts = []\n",
    "        for i, result in enumerate(results):\n",
    "            filename = result['metadata']['filename']\n",
    "            chunk_text = result['text']\n",
    "            context_parts.append(f\"[Source {i+1}: {filename}]\\n{chunk_text}\")\n",
    "        \n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        \n",
    "        # Create prompt\n",
    "        prompt = f\"\"\"You are a helpful genealogy research assistant. Answer the following question based on the provided information about ancestors.\n",
    "\n",
    "Context from ancestor documents:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Instructions:\n",
    "- Provide a clear, accurate answer based on the documents\n",
    "- Include specific details like dates, places, and names when available\n",
    "- If the documents don't contain enough information to answer fully, say so\n",
    "- Be conversational and helpful\n",
    "- Don't make up information that isn't in the documents\n",
    "\n",
    "Answer:\"\"\"\n",
    "        \n",
    "        # Query Claude\n",
    "        try:\n",
    "            message = self.client.messages.create(\n",
    "                model=\"claude-sonnet-4-20250514\",\n",
    "                max_tokens=2000,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            answer = message.content[0].text\n",
    "        except Exception as e:\n",
    "            return {\"answer\": f\"Error querying Claude: {e}\", \"sources\": []}\n",
    "        \n",
    "        # Prepare response\n",
    "        response = {\"answer\": answer}\n",
    "        if show_sources:\n",
    "            response[\"sources\"] = [\n",
    "                {\n",
    "                    \"file\": r['metadata']['filename'],\n",
    "                    \"chunk\": r['metadata']['chunk_id'],\n",
    "                    \"score\": r['score']\n",
    "                }\n",
    "                for r in results\n",
    "            ]\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def save_index(self, filepath: str = \"ancestor_index.pkl\"):\n",
    "        \"\"\"Save the document index to a file.\"\"\"\n",
    "        data = {\"documents\": self.documents, \"embeddings\": self.embeddings}\n",
    "        with open(filepath, \"wb\") as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"‚úì Index saved to {filepath} ({len(self.documents)} chunks)\")\n",
    "    \n",
    "    def load_index(self, filepath: str = \"ancestor_index.pkl\"):\n",
    "        \"\"\"Load a previously saved index.\"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"‚ùå Error: Index file '{filepath}' not found\")\n",
    "            return False\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, \"rb\") as f:\n",
    "                data = pickle.load(f)\n",
    "            self.documents = data[\"documents\"]\n",
    "            self.embeddings = data[\"embeddings\"]\n",
    "            print(f\"‚úì Index loaded from {filepath} ({len(self.documents)} chunks)\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading index: {e}\")\n",
    "            return False\n",
    "\n",
    "print(\"‚úì AncestorRAG class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Step 4: Configure API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key Configuration\n",
    "print(\"=\"*70)\n",
    "print(\"üîë API Key Setup\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if already set in environment\n",
    "API_KEY = os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "\n",
    "if API_KEY:\n",
    "    print(\"‚úì Found API key in environment variable\")\n",
    "else:\n",
    "    print(\"\\nPlease enter your Anthropic API key:\")\n",
    "    print(\"(Get one at: https://console.anthropic.com/)\")\n",
    "    from getpass import getpass\n",
    "    API_KEY = getpass(\"API Key: \")\n",
    "    \n",
    "    if API_KEY:\n",
    "        os.environ[\"ANTHROPIC_API_KEY\"] = API_KEY\n",
    "        print(\"‚úì API key set for this session\")\n",
    "    else:\n",
    "        print(\"‚ùå No API key provided\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Step 5: Ask Question BEFORE Loading Documents\n",
    "\n",
    "This establishes a baseline - what does Claude know without your documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Step 1: Ask a Question (WITHOUT your documents)\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nAsk a question about one of your ancestors.\")\n",
    "print(\"Example: 'Where was Giovanni Parone born?'\\n\")\n",
    "\n",
    "question = input(\"Your question: \").strip()\n",
    "\n",
    "if not question:\n",
    "    question = \"Where was Giovanni Parone born?\"\n",
    "    print(f\"Using default: {question}\")\n",
    "\n",
    "print(f\"\\nü§î Asking Claude WITHOUT documents...\\n\")\n",
    "\n",
    "# Ask Claude directly (no RAG)\n",
    "client = anthropic.Anthropic(api_key=API_KEY)\n",
    "try:\n",
    "    message = client.messages.create(\n",
    "        model=\"claude-sonnet-4-20250514\",\n",
    "        max_tokens=1000,\n",
    "        messages=[{\"role\": \"user\", \"content\": question}]\n",
    "    )\n",
    "    answer_without_rag = message.content[0].text\n",
    "except Exception as e:\n",
    "    answer_without_rag = f\"Error: {e}\"\n",
    "\n",
    "display(Markdown(\"### üí¨ Answer WITHOUT documents:\"))\n",
    "display(Markdown(f\"---\\n{answer_without_rag}\\n---\"))\n",
    "\n",
    "print(\"\\n‚úì Baseline answer recorded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÅ Step 6: Select and Load PDF Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Step 2: Load Your PDF Documents\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find all PDFs in current directory\n",
    "pdf_files = [f for f in os.listdir(\".\") if f.endswith(\".pdf\")]\n",
    "\n",
    "if not pdf_files:\n",
    "    print(\"\\n‚ùå No PDF files found in current directory.\")\n",
    "    print(\"Please upload PDF files and re-run this cell.\")\n",
    "else:\n",
    "    print(f\"\\nFound {len(pdf_files)} PDF file(s):\")\n",
    "    for i, pdf in enumerate(pdf_files, 1):\n",
    "        size_mb = os.path.getsize(pdf) / (1024 * 1024)\n",
    "        print(f\"  {i}. {pdf} ({size_mb:.2f} MB)\")\n",
    "    \n",
    "    # Ask user which PDFs to load\n",
    "    print(\"\\nWhich PDFs to load?\")\n",
    "    print(\"  ‚Ä¢ Enter numbers (e.g., 1,2,3)\")\n",
    "    print(\"  ‚Ä¢ Enter 'all' for all files\")\n",
    "    \n",
    "    choice = input(\"\\nChoice: \").strip().lower()\n",
    "    \n",
    "    if choice == 'all':\n",
    "        selected_pdfs = pdf_files\n",
    "    else:\n",
    "        try:\n",
    "            indices = [int(x.strip()) for x in choice.split(',')]\n",
    "            selected_pdfs = [pdf_files[i-1] for i in indices if 1 <= i <= len(pdf_files)]\n",
    "        except:\n",
    "            print(\"‚ö†Ô∏è  Invalid choice. Loading all PDFs.\")\n",
    "            selected_pdfs = pdf_files\n",
    "    \n",
    "    if selected_pdfs:\n",
    "        print(f\"\\n‚úì Will process {len(selected_pdfs)} PDF(s)\")\n",
    "    else:\n",
    "        print(\"‚ùå No PDFs selected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 7: Process PDFs with RAG (Timed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Step 3: Processing Documents (RAG)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not pdf_files or not selected_pdfs:\n",
    "    print(\"\\n‚ùå No PDFs to process. Please upload PDFs first.\")\n",
    "else:\n",
    "    print(f\"\\n‚öôÔ∏è  Loading {len(selected_pdfs)} PDF(s) into RAG system...\")\n",
    "    print(\"This will:\")\n",
    "    print(\"  1. Extract text from PDFs\")\n",
    "    print(\"  2. Split into chunks\")\n",
    "    print(\"  3. Create embeddings\")\n",
    "    print()\n",
    "    \n",
    "    # Initialize RAG\n",
    "    rag = AncestorRAG(anthropic_api_key=API_KEY)\n",
    "    print()\n",
    "    \n",
    "    # Process with timing\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for pdf in selected_pdfs:\n",
    "        rag.add_pdf(pdf)\n",
    "        print()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(f\"‚úì Processing complete!\")\n",
    "    print(f\"‚è±Ô∏è  Time: {elapsed:.2f} seconds ({elapsed/60:.2f} minutes)\")\n",
    "    print(f\"üìä Total chunks: {len(rag.documents)}\")\n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Step 8: Ask Same Question WITH Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"Step 4: Ask the Same Question (WITH your documents)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if not rag.documents:\n",
    "    print(\"\\n‚ùå No documents loaded. Please run the previous cells first.\")\n",
    "else:\n",
    "    print(f\"\\nOriginal question: \\\"{question}\\\"\")\n",
    "    change = input(\"Ask a different question? (yes/no): \").strip().lower()\n",
    "    \n",
    "    if change in ['yes', 'y']:\n",
    "        new_q = input(\"New question: \").strip()\n",
    "        if new_q:\n",
    "            question = new_q\n",
    "    \n",
    "    print(f\"\\nüîé Asking Claude WITH documents (using RAG)...\\n\")\n",
    "    \n",
    "    result = rag.query(question, top_k=5)\n",
    "    \n",
    "    display(Markdown(\"### üí¨ Answer WITH documents:\"))\n",
    "    display(Markdown(f\"---\\n{result['answer']}\\n---\"))\n",
    "    \n",
    "    if result.get('sources'):\n",
    "        print(\"\\nüìö Sources:\")\n",
    "        for i, s in enumerate(result['sources'], 1):\n",
    "            print(f\"  {i}. {s['file']} (chunk {s['chunk']}, relevance: {s['score']:.0%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Step 9: Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"# üîç COMPARISON - Before vs After RAG\"))\n",
    "display(Markdown(f\"## ‚ùì Question: {question}\\n\"))\n",
    "\n",
    "display(Markdown(\"### üî¥ BEFORE (without documents):\"))\n",
    "display(Markdown(f\"---\\n{answer_without_rag}\\n---\"))\n",
    "\n",
    "if 'result' in locals():\n",
    "    display(Markdown(\"### üü¢ AFTER (with RAG):\"))\n",
    "    display(Markdown(f\"---\\n{result['answer']}\\n---\"))\n",
    "\n",
    "display(Markdown(\"\"\"\n",
    "### üí° Key Differences:\n",
    "- **BEFORE**: Based only on Claude's general knowledge\n",
    "- **AFTER**: Based on YOUR specific documents\n",
    "- **RAG** provides accurate, sourced, personalized answers!\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ Step 10: Interactive Q&A (Ask More Questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive interface\n",
    "question_input = widgets.Textarea(\n",
    "    placeholder='Ask another question about your ancestors...',\n",
    "    description='Question:',\n",
    "    layout=widgets.Layout(width='100%', height='80px')\n",
    ")\n",
    "\n",
    "ask_button = widgets.Button(\n",
    "    description='Ask Claude',\n",
    "    button_style='primary',\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_ask_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        q = question_input.value.strip()\n",
    "        \n",
    "        if not q:\n",
    "            print(\"‚ö†Ô∏è  Please enter a question\")\n",
    "            return\n",
    "        \n",
    "        if not rag.documents:\n",
    "            print(\"‚ùå No documents loaded. Please run the cells above first.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üîé Searching for: {q}\\n\")\n",
    "        print(\"‚è≥ Generating answer...\\n\")\n",
    "        \n",
    "        result = rag.query(q)\n",
    "        \n",
    "        display(Markdown(f\"### üí¨ Answer:\\n\\n{result['answer']}\"))\n",
    "        \n",
    "        if result.get('sources'):\n",
    "            print(\"\\nüìö Sources:\")\n",
    "            for i, source in enumerate(result['sources'], 1):\n",
    "                print(f\"  {i}. {source['file']} (chunk {source['chunk']}, relevance: {source['score']:.0%})\")\n",
    "\n",
    "ask_button.on_click(on_ask_clicked)\n",
    "\n",
    "print(\"üå≥ Interactive Q&A - Ask more questions below!\")\n",
    "print()\n",
    "display(question_input)\n",
    "display(ask_button)\n",
    "display(output_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Step 11: Save Your Index (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the index to avoid re-processing next time\n",
    "if 'rag' in locals() and rag.documents:\n",
    "    save = input(\"Save the index for faster loading next time? (yes/no): \").strip().lower()\n",
    "    \n",
    "    if save in ['yes', 'y']:\n",
    "        filename = input(\"Filename (press Enter for 'ancestor_index.pkl'): \").strip()\n",
    "        if not filename:\n",
    "            filename = \"ancestor_index.pkl\"\n",
    "        \n",
    "        rag.save_index(filename)\n",
    "        print(f\"\\nüí° Next time, load with: rag.load_index('{filename}')\")\n",
    "else:\n",
    "    print(\"No index to save. Please process PDFs first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Example Questions to Try\n",
    "\n",
    "Use the interactive box above to ask:\n",
    "- Where was [name] born?\n",
    "- When did [name] immigrate to America?\n",
    "- What was [name]'s occupation?\n",
    "- Tell me about [name]'s family\n",
    "- Where did [name] live in the United States?\n",
    "- What military service did [name] have?\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "1. ‚úÖ Baseline question (without documents)\n",
    "2. ‚úÖ PDF selection and loading\n",
    "3. ‚úÖ Timed RAG processing\n",
    "4. ‚úÖ Same question with RAG\n",
    "5. ‚úÖ Before/after comparison\n",
    "6. ‚úÖ Interactive Q&A mode\n",
    "\n",
    "**Key Takeaway:** RAG transforms general AI into a personalized research assistant for YOUR documents! üå≥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
